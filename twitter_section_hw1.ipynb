{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95952cac",
   "metadata": {},
   "source": [
    "# ADS 509 Module 1: APIs and Web Scraping\n",
    "\n",
    "This notebook has three parts. In the first part you will pull data from the Twitter API. In the second, you will scrape lyrics from AZLyrics.com. In the last part, you'll run code that verifies the completeness of your data pull. \n",
    "\n",
    "For this assignment you have chosen two musical artists who have at least 100,000 Twitter followers and 20 songs with lyrics on AZLyrics.com. In this part of the assignment we pull the some of the user information for the followers of your artist and store them in text files. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a379cc4-7632-4b54-8e52-0b5304fb4a6c",
   "metadata": {},
   "source": [
    "# Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "185076b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the twitter section\n",
    "import tweepy\n",
    "import os\n",
    "import datetime\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "# for the lyrics scrape section\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a47e2d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell for any import statements you add\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "def timer(length_of_time):\n",
    "    timer = round(length_of_time / 60)\n",
    "\n",
    "    for num in range(0,timer,1):\n",
    "        time.sleep(60)\n",
    "        print(f'Sequence {num} complete out of {timer}.')\n",
    "        \n",
    "    print('Ring Ring Ring')\n",
    "    \n",
    "def folder_maker(folder2make):\n",
    "    # create directory to store html files\n",
    "    if os.path.isdir(folder2make):\n",
    "        shutil.rmtree(folder2make)\n",
    "    os.mkdir(folder2make)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c8969e",
   "metadata": {},
   "source": [
    "# Twitter API Pull"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21c86ec",
   "metadata": {},
   "source": [
    "We need bring in our API keys. Since API keys should be kept secret, we'll keep them in a file called `api_keys.py`. This file should be stored in the directory where you store this notebook. The example file is provided for you on Blackboard. The example has API keys that are _not_ functional, so you'll need to get Twitter credentials and replace the placeholder keys. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d0dcd50-3573-4491-bbdd-294b3b0cc0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from api_keys import api_key, api_key_secret, bearer_token\n",
    "\n",
    "def client_FN():\n",
    "    return tweepy.Client(bearer_token,wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa67032",
   "metadata": {},
   "source": [
    "# Testing the API\n",
    "\n",
    "The Twitter APIs are quite rich. Let's play around with some of the features before we dive into this section of the assignment. For our testing, it's convenient to have a small data set to play with. We will seed the code with the handle of John Chandler, one of the instructors in this course. His handle is `@37chandler`. Feel free to use a different handle if you would like to look at someone else's data. \n",
    "\n",
    "We will write code to explore a few aspects of the API: \n",
    "\n",
    "1. Pull some of the followers @37chandler.\n",
    "1. Explore response data, which gives us information about Twitter users. \n",
    "1. Pull the last few tweets by @37chandler.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76cf6447",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = client_FN()\n",
    "\n",
    "handle = \"37chandler\"\n",
    "chandler_user_data = client.get_user(username=handle)\n",
    "\n",
    "chandler_followers = client.get_users_followers(\n",
    "    # https://developer.twitter.com/en/docs/twitter-api/data-dictionary/object-model/user\n",
    "    chandler_user_data.data.id, user_fields=[\"created_at\",\"description\",\"location\",\n",
    "                                   \"public_metrics\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7892a4",
   "metadata": {},
   "source": [
    "Now let's explore these a bit. We'll start by printing out names, locations, following count, and followers count for these users. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c48d6bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dave Renn lists 'None' as their location.\n",
      " Following: 42, Followers: 11.\n",
      "\n",
      "Lionel lists 'None' as their location.\n",
      " Following: 202, Followers: 204.\n",
      "\n",
      "Megan Randall lists 'None' as their location.\n",
      " Following: 141, Followers: 100.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_to_print = 3\n",
    "\n",
    "for idx, user in enumerate(chandler_followers.data) :\n",
    "    following_count = user.public_metrics['following_count']\n",
    "    followers_count = user.public_metrics['followers_count']\n",
    "    \n",
    "    print(f\"{user.name} lists '{user.location}' as their location.\")\n",
    "    print(f\" Following: {following_count}, Followers: {followers_count}.\\n\")\n",
    "    \n",
    "    if idx >= (num_to_print - 1) :\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbfe05f",
   "metadata": {},
   "source": [
    "Let's find the person who follows this handle who has the most followers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bda3eec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WedgeLIVE\n",
      "{'followers_count': 14157, 'following_count': 2223, 'tweet_count': 56071, 'listed_count': 218}\n"
     ]
    }
   ],
   "source": [
    "max_followers = 0\n",
    "\n",
    "for idx, user in enumerate(chandler_followers.data) :\n",
    "    followers_count = user.public_metrics['followers_count']\n",
    "    \n",
    "    if followers_count > max_followers :\n",
    "        max_followers = followers_count\n",
    "        max_follower_user = user\n",
    "\n",
    "print(max_follower_user)\n",
    "print(max_follower_user.public_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dad0a3f",
   "metadata": {},
   "source": [
    "Let's pull some more user fields and take a look at them. The fields can be specified in the `user_fields` argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb69f9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = client.get_user(id=chandler_user_data.data.id,\n",
    "#                           user_fields=[\"created_at\",\"description\",\"location\",\n",
    "#                                        \"entities\",\"name\",\"pinned_tweet_id\",\"profile_image_url\",\n",
    "#                                        \"verified\",\"public_metrics\"])\n",
    "\n",
    "# for i, (field, value) in enumerate(response.data.items()):\n",
    "#     print(f\"for {field} we have {value}\")\n",
    "# print(f\"\\n\\nThere are a total of {i+1} fields!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abc5dc6",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "Now a few questions for you about the user object.\n",
    "\n",
    "<u>Q: How many fields are being returned in this user object?</u>\n",
    "\n",
    "A: There is a total of 9 fields.\n",
    "\n",
    "---\n",
    "\n",
    "<u>Q: Are any of the fields within the user object non-scalar? (I.e., more complicated than a simple data type like integer, float, string, boolean, etc.)</u>\n",
    "\n",
    "A: Public Metrics is a Dict containing scalar-values, profile_image_url contains a url string, date time as \"created_at\", and last but not least \"description\" is also a string.\n",
    "\n",
    "---\n",
    "<u>Q: How many friends, followers, and tweets does this user have? </u>\n",
    "\n",
    "A:<br>\n",
    "followers count: 194<br>\n",
    "following count: 590<br>\n",
    "tweet count: 989<br>\n",
    "listed count: 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8564d2c",
   "metadata": {},
   "source": [
    "Although you won't need it for this assignment, individual tweets can be a rich source of text-based data. To illustrate the concepts, let's look at the last few tweets for this user. You are encouraged to explore the fields that are available about Tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70b8e93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = client.get_users_tweets(chandler_user_data.data.id)\n",
    "\n",
    "# # By default, only the ID and text fields of each Tweet will be returned\n",
    "# for idx, tweet in enumerate(response.data) :\n",
    "#     print(tweet.id)\n",
    "#     print(tweet.text)\n",
    "#     print()\n",
    "    \n",
    "#     if idx > 5:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d50726",
   "metadata": {},
   "source": [
    "## Pulling Follower Information\n",
    "\n",
    "In this next section of the assignment, we will pull information about the followers of your two artists. We've seen above how to pull a set of followers using `client.get_users_followers`. This function has a parameter, `max_results`, that we can use to change the number of followers that we pull. Unfortunately, we can only pull 1000 followers at a time, which means we will need to handle the _pagination_ of our results. \n",
    "\n",
    "The return object has the `.data` field, where the results will be found. It also has `.meta`, which we use to select the next \"page\" in the results using the `next_token` result. I will illustrate the ideas using our user from above. \n",
    "\n",
    "\n",
    "### Rate Limiting\n",
    "\n",
    "Twitter limits the rates at which we can pull data, as detailed in [this guide](https://developer.twitter.com/en/docs/twitter-api/rate-limits). We can make 15 user requests per 15 minutes, meaning that we can pull $4 \\cdot 15 \\cdot 1000 = 60000$ users per hour. I illustrate the handling of rate limiting below, though whether or not you hit that part of the code depends on your value of `handle`.  \n",
    "\n",
    "\n",
    "In the below example, I'll pull all the followers, 25 at a time. (We're using 25 to illustrate the idea; when you do this set the value to 1000.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5236335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle_followers = []\n",
    "# pulls = 0\n",
    "# max_pulls = 100\n",
    "# next_token = None\n",
    "# max_results = 2 # when you do this for real, set this to 1000!\n",
    "\n",
    "# while True :\n",
    "\n",
    "#     followers = client.get_users_followers(\n",
    "#         chandler_user_data.data.id, \n",
    "#         max_results=max_results, \n",
    "#         pagination_token = next_token,\n",
    "#         user_fields=needed_fields\n",
    "#     )\n",
    "#     pulls += 1\n",
    "    \n",
    "#     for follower in followers.data : \n",
    "#         follower_row = (follower.id,follower.name,follower.created_at,follower.description)\n",
    "#         handle_followers.append(follower_row)\n",
    "    \n",
    "#     if 'next_token' in followers.meta and pulls < max_pulls :\n",
    "#         next_token = followers.meta['next_token']\n",
    "#     else : \n",
    "#         break\n",
    "\n",
    "# handle_followers[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3ec0e5",
   "metadata": {},
   "source": [
    "Now let's take a look at your artists and see how long it is going to take to pull all their followers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b37383c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It would take 11.27 hours to pull all 675974 followers for FFDP. \n",
      "It would take 5.02 hours to pull all 301231 followers for OfficialRezz. \n"
     ]
    }
   ],
   "source": [
    "artists = dict()\n",
    "\n",
    "handles = ['FFDP','OfficialRezz']\n",
    "\n",
    "client = client_FN()\n",
    "for handle in handles: \n",
    "    user_obj = client.get_user(username=handle,user_fields=[\"public_metrics\"])\n",
    "    artists[handle] = (user_obj.data.id, \n",
    "                       handle,\n",
    "                       user_obj.data.public_metrics['followers_count'])\n",
    "\n",
    "for artist, data in artists.items() : \n",
    "    print(f\"It would take {data[2]/(1000*15*4):.2f} hours to pull all {data[2]} followers for {artist}. \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6ed3f9",
   "metadata": {},
   "source": [
    "Depending on what you see in the display above, you may want to limit how many followers you pull. It'd be great to get at least 200,000 per artist. \n",
    "\n",
    "As we pull data for each artist we will write their data to a folder called \"twitter\", so we will make that folder if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3a32641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the \"twitter\" folder here. If you'd like to practice your programming, add functionality \n",
    "# that checks to see if the folder exists. If it does, then \"unlink\" it. Then create a new one.\n",
    "\n",
    "# checks to see if current dir has folder named twitter\n",
    "if os.path.isdir(\"twitter\"): \n",
    "    shutil.rmtree(\"twitter/\")\n",
    "\n",
    "os.mkdir(\"twitter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd58dd90",
   "metadata": {},
   "source": [
    "In the following cells, build on the above code to pull some of the followers and their data for your two artists. As you pull the data, write the follower ids to a file called `[artist name]_followers.txt` in the \"twitter\" folder. For instance, for Cher I would create a file named `cher_followers.txt`. As you pull the data, also store it in an object like a list or a data frame.\n",
    "\n",
    "Extract and store the following fields: \n",
    "\n",
    "* screen_name\t\n",
    "* name\t\n",
    "* id\t\n",
    "* location\t\n",
    "* followers_count\t\n",
    "* friends_count\t\n",
    "* description\n",
    "\n",
    " Store the fields with one user per row in a tab-delimited text file with the name `[artist name]_follower_data.txt`. For instance, for Cher I would create a file named `cher_follower_data.txt`. \n",
    "\n",
    "\n",
    "One note: the user's description can have tabs or returns in it, so make sure to clean those out of the description before writing them to the file. I've included some example code to do that below the stub. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11b41e6f-20d0-452e-b119-e46160508ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FFDP\n",
      "Current Count: 15000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Sleeping for 888 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Count: 30000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Sleeping for 888 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Count: 45000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Sleeping for 888 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Count: 60000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Sleeping for 888 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Count: 75000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Sleeping for 887 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Count: 90000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Sleeping for 888 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Count: 105000\n",
      "\n",
      "1:32:33.683915\n"
     ]
    }
   ],
   "source": [
    "max_results = 1000\n",
    "max_pulls = 100\n",
    "next_token=None\n",
    "pulls = 0\n",
    "# Grabs the time when we start making requests to the API\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "num_followers_to_pull = 200*1000\n",
    "\n",
    "for handle in handles:\n",
    "    print(f'Processing {handle}')\n",
    "    client = client_FN()\n",
    "    user_data = client.get_user(username=handle)\n",
    "    \n",
    "    follower_data = []\n",
    "    follower_ids = []\n",
    "    current_follower_count = 0\n",
    "    \n",
    "    needed_fields = ['description',\n",
    "                     'id',\n",
    "                     'location',\n",
    "                     'name',\n",
    "                     'public_metrics']\n",
    "\n",
    "    while True :\n",
    "        try:\n",
    "            current_follower_count += max_results\n",
    "            \n",
    "            # print status/current count during pagination/pause\n",
    "            if current_follower_count % 15000 == 0:\n",
    "                print(f'Current Count: {current_follower_count}\\n')\n",
    "            # restablish connection via new connection\n",
    "            client = client_FN()\n",
    "\n",
    "            followers = client.get_users_followers(\n",
    "                user_data.data.id, \n",
    "                max_results=max_results, \n",
    "                pagination_token=next_token,\n",
    "                user_fields=needed_fields\n",
    "            )\n",
    "            pulls += 1\n",
    "            \n",
    "            \n",
    "            for follower in followers.data:\n",
    "                follower_ids.append(follower.id)\n",
    "\n",
    "                follower_row = {'Artist':handle,\n",
    "                                'Id':follower.id,\n",
    "                                'Name':follower.name,\n",
    "                                'User_Name':follower.username, # screen_name\n",
    "                                'Description':follower.description,\n",
    "                                'Location':follower.location,\n",
    "                                'Followers_Count':follower.public_metrics['followers_count']}\n",
    "                follower_data.append(follower_row)\n",
    "\n",
    "                \n",
    "            if 'next_token' in followers.meta and pulls < max_pulls :\n",
    "                next_token = followers.meta['next_token']\n",
    "            # If num of followers pulled reaches designated limit num_followers_to_pull\n",
    "            elif current_follower_count > num_followers_to_pull:\n",
    "                break\n",
    "            else : \n",
    "                break\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Write the data to the output file in the `twitter` folder.\n",
    "    pd.DataFrame(follower_data).to_csv(f'twitter/{handle}_followers_data.txt', index=False, sep='\\t')\n",
    "    \n",
    "    pd.Series({handle:follower_ids}).to_csv(f'twitter/{handle}_followers.txt', index=False, sep='\\t')\n",
    "\n",
    "# Let's see how long it took to grab all follower IDs\n",
    "end_time = datetime.datetime.now()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355357d3-f341-418a-9da6-9f96d06db03f",
   "metadata": {},
   "source": [
    "#### Check Saved Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec7798e-18d3-4391-be79-b14fa7626a90",
   "metadata": {},
   "source": [
    "The file for Rezz was unreadable to Pandas, but readable to MacOS's Numbers software, which I loaded the text file into, tell the software the deliminator type and exported the file as a CSV which is used in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2311694f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Home by Warsan Shire no one leaves home unless home is the mouth of a shark. you only run for the border when you see the whole city running as well. '"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tricky_description = \"\"\"\n",
    "    Home by Warsan Shire\n",
    "    \n",
    "    no one leaves home unless\n",
    "    home is the mouth of a shark.\n",
    "    you only run for the border\n",
    "    when you see the whole city\n",
    "    running as well.\n",
    "\n",
    "\"\"\"\n",
    "# This won't work in a tab-delimited text file.\n",
    "\n",
    "clean_description = re.sub(r\"\\s+\",\" \",tricky_description)\n",
    "clean_description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054cf14b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "This assignment asks you to pull data from the Twitter API and scrape www.AZLyrics.com.  After you have finished the above sections , run all the cells in this notebook. Print this to PDF and submit it, per the instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "217c2b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple word extractor from Peter Norvig: https://norvig.com/spell-correct.html\n",
    "def words(text): \n",
    "    return re.findall(r'\\w+', text.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9290b4c3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Checking Twitter Data\n",
    "\n",
    "The output from your Twitter API pull should be two files per artist, stored in files with formats like `cher_followers.txt` (a list of all follower IDs you pulled) and `cher_followers_data.txt`. These files should be in a folder named `twitter` within the repository directory. This code summarizes the information at a high level to help the instructor evaluate your work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d2174c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We see two artist handles: OfficialRezz and FFDP.\n"
     ]
    }
   ],
   "source": [
    "twitter_files = os.listdir(\"twitter\")\n",
    "twitter_files = [f for f in twitter_files if f != \".DS_Store\"]\n",
    "artist_handles = list(set([name.split(\"_\")[0] for name in twitter_files]))\n",
    "\n",
    "print(f\"We see two artist handles: {artist_handles[0]} and {artist_handles[1]}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e295ab5d-9e4d-46cd-8a61-c0de49ff3dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OfficialRezz', 'FFDP']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist_handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7ad545be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We see 1 in your follower file for OfficialRezz, assuming a header row.\n",
      "In the follower data file (OfficialRezz_followers_data.txt) for OfficialRezz, we have these columns:\n",
      "Artist : Id : Name : User_Name : Description : Location : Followers_Count\n",
      "\n",
      "We have 122520 data rows for OfficialRezz in the follower data file.\n",
      "For OfficialRezz we have 99997 unique locations.\n",
      "For OfficialRezz we have 181374 words in the descriptions.\n",
      "Here are the five most common words:\n",
      "[('0', 95739), ('1', 4175), ('2', 3221), ('3', 2612), ('4', 2117)]\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "We see 1 in your follower file for FFDP, assuming a header row.\n",
      "In the follower data file (FFDP_followers_data.txt) for FFDP, we have these columns:\n",
      "Artist : Id : Name : User_Name : Description : Location : Followers_Count\n",
      "\n",
      "We have 122213 data rows for FFDP in the follower data file.\n",
      "For FFDP we have 99996 unique locations.\n",
      "For FFDP we have 91065 words in the descriptions.\n",
      "Here are the five most common words:\n",
      "[('0', 11610), ('1', 8819), ('2', 6471), ('3', 4787), ('4', 3811)]\n",
      "\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for artist in artist_handles :\n",
    "    follower_file = artist + \"_followers.txt\"\n",
    "    follower_data_file = artist + \"_followers_data.txt\"\n",
    "    \n",
    "    ids = open(\"twitter/\" + follower_file,'r').readlines()\n",
    "    \n",
    "    print(f\"We see {len(ids)-1} in your follower file for {artist}, assuming a header row.\")\n",
    "    \n",
    "    with open(\"twitter/\" + follower_data_file,'r') as infile :\n",
    "        \n",
    "        # check the headers\n",
    "        headers = infile.readline().split(\"\\t\")\n",
    "        \n",
    "        print(f\"In the follower data file ({follower_data_file}) for {artist}, we have these columns:\")\n",
    "        print(\" : \".join(headers))\n",
    "        \n",
    "        description_words = []\n",
    "        locations = set()\n",
    "        \n",
    "        \n",
    "        for idx, line in enumerate(infile.readlines()) :\n",
    "            line = line.strip(\"\\n\").split(\"\\t\")\n",
    "            \n",
    "            try : \n",
    "                locations.add(line[3])            \n",
    "                description_words.extend(words(line[6]))\n",
    "            except :\n",
    "                pass\n",
    "    \n",
    "        \n",
    "\n",
    "        print(f\"We have {idx+1} data rows for {artist} in the follower data file.\")\n",
    "\n",
    "        print(f\"For {artist} we have {len(locations)} unique locations.\")\n",
    "\n",
    "        print(f\"For {artist} we have {len(description_words)} words in the descriptions.\")\n",
    "        print(\"Here are the five most common words:\")\n",
    "        print(Counter(description_words).most_common(5))\n",
    "\n",
    "        \n",
    "        print(\"\")\n",
    "        print(\"-\"*40)\n",
    "        print(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37778a1c",
   "metadata": {},
   "source": [
    "## Checking Lyrics \n",
    "\n",
    "The output from your lyrics scrape should be stored in files located in this path from the directory:\n",
    "`/lyrics/[Artist Name]/[filename from URL]`. This code summarizes the information at a high level to help the instructor evaluate your work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bccac29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For robyn we have 22 files.\n",
      "For robyn we have roughly 9116 words, 1011 are unique.\n",
      "For cher we have 22 files.\n",
      "For cher we have roughly 8935 words, 1280 are unique.\n"
     ]
    }
   ],
   "source": [
    "artist_folders = os.listdir(\"lyrics/\")\n",
    "artist_folders = [f for f in artist_folders if os.path.isdir(\"lyrics/\" + f)]\n",
    "\n",
    "for artist in artist_folders : \n",
    "    artist_files = os.listdir(\"lyrics/\" + artist)\n",
    "    artist_files = [f for f in artist_files if 'txt' in f or 'csv' in f or 'tsv' in f]\n",
    "\n",
    "    print(f\"For {artist} we have {len(artist_files)} files.\")\n",
    "\n",
    "    artist_words = []\n",
    "\n",
    "    for f_name in artist_files : \n",
    "        with open(\"lyrics/\" + artist + \"/\" + f_name) as infile : \n",
    "            artist_words.extend(words(infile.read()))\n",
    "\n",
    "            \n",
    "    print(f\"For {artist} we have roughly {len(artist_words)} words, {len(set(artist_words))} are unique.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
